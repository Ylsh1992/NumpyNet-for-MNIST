{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a neural network to classify MNIST by numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data: Load by your path not only MNIST dataset, you can choose any dataset suit for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('./MNIST')\n",
    "train_img_path = data_path/'train-images-idx3-ubyte'\n",
    "train_lab_path = data_path/'train-labels-idx1-ubyte'\n",
    "test_img_path = data_path/'t10k-images-idx3-ubyte'\n",
    "test_lab_path = data_path/'t10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and labels\n",
    "\n",
    "# For training convenient, we set number of train to 5000.\n",
    "num_train = 5000\n",
    "num_valid = 10000\n",
    "num_test = 10000\n",
    "\n",
    "with open(train_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    tmp_img = np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)\n",
    "    train_img = tmp_img[:num_train]\n",
    "    valid_img = tmp_img[num_train:]\n",
    "    \n",
    "with open(test_img_path,'rb') as f:\n",
    "    struct.unpack('>4i',f.read(16))\n",
    "    test_img = np.fromfile(f,dtype=np.uint8).reshape(-1,28*28)\n",
    "\n",
    "with open(train_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    tmp_lab = np.fromfile(f,dtype=np.uint8)\n",
    "    train_lab = tmp_lab[:num_train]\n",
    "    valid_lab = tmp_lab[num_train:]\n",
    "    \n",
    "with open(test_lab_path,'rb') as f:\n",
    "    struct.unpack('>2i',f.read(8))\n",
    "    test_lab = np.fromfile(f,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(dataset = 'train', index = 666):\n",
    "    if dataset == 'train':\n",
    "        print('Trainning set:')\n",
    "        plt.imshow(train_img[index].reshape(28,28), cmap = 'gray')\n",
    "        print(f'Label: {train_lab[index]}')\n",
    "    elif dataset == 'val':\n",
    "        print('Validation set:')\n",
    "        plt.imshow(valid_img[index].reshape(28,28), cmap = 'gray')\n",
    "        print(f'Label: {valid_lab[index]}')\n",
    "    elif dataset == 'test':\n",
    "        print('Test set:')\n",
    "        plt.imshow(test_img[index].reshape(28,28), cmap = 'gray')\n",
    "        print(f'Label: {test_lab[index]}')\n",
    "    else:\n",
    "        print(f'No {dataset} dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning set:\n",
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgshow('train',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the onehot encoding\n",
    "onehot = np.identity(10)\n",
    "onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def para_shape(layer_dims):\n",
    "    parameters_shape = []\n",
    "    for i in range(1,len(layer_dims)):\n",
    "        dict_para = {'b'+str(i):layer_dims[i], 'W'+str(i):[layer_dims[i],layer_dims[i-1]]}\n",
    "        parameters_shape.append(dict_para)\n",
    "    return parameters_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'b1': 4, 'W1': [4, 5]}, {'b2': 3, 'W2': [3, 4]}, {'b3': 10, 'W3': [10, 3]}]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = [5, 4, 3, 10] # input:28*28, layer1(output):10\n",
    "layer_activations = ['tanh', 'tanh', 'softmax']\n",
    "parameters_shape = para_shape(layer_dims)\n",
    "parameters_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_bias(b):\n",
    "    return np.zeros(b).reshape(-1,1)\n",
    "\n",
    "def init_weight(w):\n",
    "#     Random initialization\n",
    "#     return np.random.randn(w[0],w[1])  \n",
    "\n",
    "#     Xavier initialization\n",
    "#     return np.random.randn(w[0],w[1])*np.sqrt(2/w[1])\n",
    "\n",
    "#     Random initialization within a small range\n",
    "    return np.random.randn(w[0],w[1])*0.1\n",
    "\n",
    "def init_parameters(para_shp):\n",
    "    parameters = {}\n",
    "    for i in range(1,len(para_shp)+1):\n",
    "        para = {'b'+str(i):init_bias(para_shp[i-1]['b'+str(i)]), 'W'+str(i):init_weight(para_shp[i-1]['W'+str(i)])}\n",
    "        parameters.update(para)\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W1': array([[ 0.16243454, -0.06117564, -0.05281718, -0.10729686,  0.08654076],\n",
       "        [-0.23015387,  0.17448118, -0.07612069,  0.03190391, -0.02493704],\n",
       "        [ 0.14621079, -0.20601407, -0.03224172, -0.03840544,  0.11337694],\n",
       "        [-0.10998913, -0.01724282, -0.08778584,  0.00422137,  0.05828152]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.11006192,  0.11447237,  0.09015907,  0.05024943],\n",
       "        [ 0.09008559, -0.06837279, -0.01228902, -0.09357694],\n",
       "        [-0.02678881,  0.05303555, -0.06916608, -0.03967535]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-0.06871727, -0.08452056, -0.06712461],\n",
       "        [-0.00126646, -0.11173103,  0.02344157],\n",
       "        [ 0.16598022,  0.07420442, -0.01918356],\n",
       "        [-0.0887629 , -0.07471583,  0.16924546],\n",
       "        [ 0.00508078, -0.06369956,  0.01909155],\n",
       "        [ 0.21002551,  0.0120159 ,  0.06172031],\n",
       "        [ 0.03001703, -0.03522498, -0.11425182],\n",
       "        [-0.03493427, -0.02088942,  0.05866232],\n",
       "        [ 0.08389834,  0.09311021,  0.02855873],\n",
       "        [ 0.08851412, -0.07543979,  0.12528682]])}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = init_parameters(parameters_shape)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the parameters shape\n",
    "parameters['W2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x), x\n",
    "\n",
    "def softmax(x):\n",
    "    exp = np.exp(x-x.max())    # if we do not minus the x.max(), the result will be explode.\n",
    "    return exp/exp.sum(axis=0, keepdims=True), x\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x), x\n",
    "\n",
    "def Prelu(x):\n",
    "    pass\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x)), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A_prev, W, b):\n",
    "    Z = np.dot(W,A_prev) + b\n",
    "    cache = (A_prev,W,b)    \n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == 'tanh':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = tanh(Z)\n",
    "    elif activation == 'softmax':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    elif activation == 'relu':\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == 'Prelu':\n",
    "        pass\n",
    "    elif activation == 'sigmoid':\n",
    "        pass\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def model_forward(X, parameters, activations):\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    num_layers = len(parameters)//2\n",
    "    \n",
    "    for i in range(1,num_layers):\n",
    "        A_prev = A\n",
    "        W = parameters['W'+str(i)]\n",
    "        b = parameters['b'+str(i)]\n",
    "        A,cache = linear_activation_forward(A_prev, W, b, activations[i-1])\n",
    "        caches.append(cache)\n",
    "        \n",
    "    Y_pred, cache = linear_activation_forward(A,parameters['W'+str(num_layers)],parameters['b'+str(num_layers)],activations[-1])\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return Y_pred, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cost\n",
    "def compute_cost(Y_pred,Y_true):\n",
    "\n",
    "    m = Y_true.shape[1]\n",
    "    cost = -np.sum(Y_true*np.log(Y_pred))/m\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev,W,b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = (1/m)*np.dot(dZ,np.transpose(A_prev))\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(np.transpose(W),dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def activation_backward(dA, cache, activation):\n",
    "#     print(\"linear_activation_backward\")\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == 'tanh':\n",
    "        dZ = d_tanh(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    elif activation == 'relu':\n",
    "        dZ = d_relu(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    elif activation == 'Prelu':\n",
    "        dZ = d_relu(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    elif activation == 'sigmoid':\n",
    "        pass\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def last_layer_backprop(dA, Y_true, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == 'softmax':\n",
    "        dZ = dA - Y_true\n",
    "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\n",
    "    elif activation == 'sigmoid':\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back pass\n",
    "\n",
    "def model_backward(Y_pred, Y_true, activations, caches):\n",
    "\n",
    "    gradients = {}\n",
    "    num_layers = len(caches)\n",
    "    Y_true = Y_true.reshape(Y_pred.shape)\n",
    "    \n",
    "    dA = Y_pred \n",
    "    cur_cache = caches[-1]\n",
    "    cur_activation = activations[-1]\n",
    "    gradients[\"dA\"+str(num_layers-1)],gradients[\"dW\"+str(num_layers)],gradients[\"db\"+str(num_layers)] = last_layer_backprop(dA, Y_true, cur_cache, cur_activation)\n",
    "\n",
    "    for l in reversed(range(num_layers-1)):\n",
    "        cur_cache = caches[l]\n",
    "        cur_activation = activations[l]\n",
    "        dA_prev_temp,dW_temp,db_temp = activation_backward(gradients[\"dA\"+str(l+1)], cur_cache, cur_activation)\n",
    "        gradients[\"dA\" + str(l)] = dA_prev_temp\n",
    "        gradients[\"dW\" + str(l + 1)] = dW_temp\n",
    "        gradients[\"db\" + str(l + 1)] = db_temp\n",
    "        \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update parameter\n",
    "\n",
    "def update_para(parameters,grads,learning_rate=0.001):\n",
    "\n",
    "    num_layers = len(parameters)//2\n",
    "    for l in range(num_layers):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l+1)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivate of activation\n",
    "\n",
    "def d_softmax(dA, Y_true, cache):\n",
    "    dZ = dA - Y_true\n",
    "    dZ = dZ/dZ.shape[1]\n",
    "    return dZ\n",
    "\n",
    "def d_tanh(dA, cache):\n",
    "    Z = cache\n",
    "    return 1 - np.tanh(dA)**2\n",
    "\n",
    "def d_relu(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z<=0] = 0\n",
    "    return dZ\n",
    "\n",
    "def d_sigmoid(dA, cache):\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)    \n",
    "    return dZ\n",
    "\n",
    "def d_Prelu(dA,cache):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build neu_net\n",
    "def build_network(X,Y,layer_dims,layer_activations,num_iterations,learning_rate=0.01,print_cost=False):\n",
    "    costs=[]\n",
    "    # Initial parameters.\n",
    "    parameter_shape = para_shape(layer_dims)\n",
    "    parameters = init_parameters(parameter_shape)\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: \n",
    "        Y_pred, caches = model_forward(X, parameters, layer_activations)\n",
    "\n",
    "        # Compute cost.\n",
    "        cost = compute_cost(Y_pred, Y)\n",
    "    \n",
    "        # Backward propagation:\n",
    "        grads = model_backward(Y_pred, Y, layer_activations, caches)\n",
    "#         break\n",
    "        # Update parameters.\n",
    "        parameters = update_para(parameters,grads,learning_rate=learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot[train_lab].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 7.624379\n",
      "Cost after iteration 100: 1.043654\n",
      "Cost after iteration 200: 0.645908\n",
      "Cost after iteration 300: 0.501640\n",
      "Cost after iteration 400: 0.401322\n",
      "Cost after iteration 500: 0.346719\n",
      "Cost after iteration 600: 0.299721\n",
      "Cost after iteration 700: 0.263745\n",
      "Cost after iteration 800: 0.236090\n",
      "Cost after iteration 900: 0.210043\n",
      "Cost after iteration 1000: 0.189811\n",
      "Cost after iteration 1100: 0.171249\n",
      "Cost after iteration 1200: 0.155207\n",
      "Cost after iteration 1300: 0.141475\n",
      "Cost after iteration 1400: 0.127629\n",
      "Cost after iteration 1500: 0.116170\n",
      "Cost after iteration 1600: 0.106246\n",
      "Cost after iteration 1700: 0.096596\n",
      "Cost after iteration 1800: 0.088260\n",
      "Cost after iteration 1900: 0.080703\n",
      "Cost after iteration 2000: 0.074198\n",
      "Cost after iteration 2100: 0.067810\n",
      "Cost after iteration 2200: 0.062268\n",
      "Cost after iteration 2300: 0.057102\n",
      "Cost after iteration 2400: 0.052465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input 28*28, Output 10: Size depend on the dataset.\n",
    "layers_dims = [28*28,30,20,10,10]\n",
    "layer_activations = ['relu', 'relu','relu', 'softmax']\n",
    "\n",
    "parameters = build_network(train_img.transpose(), onehot[train_lab].transpose(), layers_dims, layer_activations, num_iterations = 2500, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
